This article is more than 2 years old
The Guardian’s approach to generative AI
This article is more than 2 years old
Fri 16 Jun 2023 05.50 EDT
Last modified on Fri 16 Jun 2023 06.31 EDT
Share
Over the last three months, colleagues from our editorial, creative, engineering, product, legal, commercial and partnerships teams have set up a Guardian AI working group to consider how we respond to these risks and opportunities and to draft a set of Guardian-wide AI principles. We’ve also been studying other media organisations’ statements and approaches with interest.
So today we’re publishing three broad principles setting out how we will and won’t use GenAI tools, as follows:
For the benefit of readers
GenAI tools are exciting but are currently unreliable. There is no room for unreliability in our journalism, nor our marketing, creative and engineering work. At a simple level, this means that the use of genAI requires human oversight. We will seek to use genAI tools editorially only where it contributes to the creation and distribution of original journalism. We will guard against the dangers of bias embedded within generative tools and their underlying training sets. If we wish to include significant elements generated by AI in a piece of work, we will only do so with clear evidence of a specific benefit, human oversight, and the explicit permission of a senior editor. We will be open with our readers when we do this.
For the benefit of our mission, our staff and the wider organisation
The Guardian has always been a fast adopter of emerging technologies that support our mission, our journalism and our staff, and we are more than the sum of our parts. When we use genAI, we will focus on situations where it can improve the quality of our work, for example by helping journalists interrogate large data sets, assisting colleagues through corrections or suggestions, creating ideas for marketing campaigns, or reducing the bureaucracy of time-consuming business processes. Any use of these tools will focus on what is valuable and worth protecting at the Guardian: “ serious reporting that takes time and effort, carefully uncovers the facts, holds the powerful to account, and interrogates ideas and arguments ”.
With respect for those who create and own content
Many genAI models are opaque systems trained on material that is harvested without the knowledge or consent of its creators. Our investment in journalism generates revenues as we license that material for reuse around the world. A guiding principle for the tools and models we consider using will be the degree to which they have considered key issues such as permissioning, transparency and fair reward. Any use we make of genAI tools does not mean a waiver of any rights in our underlying content.
The Guardian was born 202 years ago in a world of huge technological change and innovation and has prospered since through a series of fundamental changes to the way we produce and distribute our journalism. We don’t yet know the full impact that these new technologies will have on our society, but we feel sure that trusted media organisations which prioritise intelligent original reporting, uncovering facts, holding the powerful to account, and interrogating ideas will be as important as ever before.
Explore more on these topics

